{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"<p>Agentic makes it easy to create AI agents - autonomous software programs that understand natural language and can use tools to do work on your behalf.</p> <p>In the tradition of opinionated frameworks, we've tried to encode lots of sensible defaults and best practices into the design, testing and deployment of agents. </p> <p>Agentic is composed of multiple parts:</p> <ul> <li>A code framework for implementing AI agents</li> <li>A runtime for deploying your agents</li> <li>A reference implementation of the Agent Protocol which defines interoperability between agents using different stacks</li> </ul> <p>Some key features:</p> <ul> <li>Approachable and simple to use, but flexible enough to support the most complex agents</li> <li>Supports teams of cooperating agents</li> <li>Supports Human-in-the-loop</li> <li>Thin, readable abstractions.</li> <li>Built in library of production-tested tools</li> </ul> <p>But there is much more. The rest of this guide will go over getting started with the framework. You can find some more background info in these docs:</p>"},{"location":"#install","title":"Install","text":"<p><code>pip install agentic-framework</code></p> <p>Or using a virtual environmment:</p> <pre><code>mkdir myagents\ncd myagents\npython -m venv .venv\nsource .venv/bin/activate\n\npip install agentic-framework\n</code></pre> <p>Now setup your folder to hold your agents:</p> <pre><code>agentic init .\n</code></pre> <p>The install will copy examples and a basic file structure into the directory <code>myagents</code>. You can name or rename this folder however you like.</p>"},{"location":"#intro-tutorial","title":"Intro Tutorial","text":"<p>Let's build our first agent. We'll start with the \"Hello World\" of agents, an agent which can give us a weather report.</p> <p>Create a new file <code>./agents/weather.py</code>, and add this code:</p> <pre><code>from agentic.common import Agent, AgentRunner\nfrom agentic.tools.weather_tool import WeatherTool\n\nweather_agent = Agent(\n    name=\"Weather Agent\",\n    welcome=\"I can give you some weather reports! Just tell me which city.\",\n    instructions=\"You are a helpful assistant.\",\n    tools=[WeatherTool()],\n    model=\"openai/gpt-4o-mini\"\n)\n\nif __name__ == \"__main__\":\n    AgentRunner(weather_agent).repl_loop()\n</code></pre> <p>Now let's run our agent. Note that you will need to configure your OpenAI API key. If you want to use a different LLM, including running a model locally, see the intstructions at models.</p> <pre><code>    agentic set-secret OPENAI_API_KEY=&lt;your key&gt;\n</code></pre> <pre><code>(.venv) % python agents/weather.py \nI can give you some weather reports! Just tell me which city.\npress &lt;ctrl-d&gt; to quit\n[Weather Agent]&gt; what is the weather like in NYC?\nThe current weather in New York City is as follows:\n\n- **Temperature:** 0.5\u00b0C\n- **Feels Like:** -4.9\u00b0C\n- **Wind Speed:** 22.9 km/h\n- **Wind Direction:** 278\u00b0 (from the west)\n- **Wind Gusts:** 45.0 km/h\n- **Precipitation:** 0.0 mm\n- **Cloud Cover:** 0%\n- **Relative Humidity:** 53%\n- **Visibility:** 37,000 m\n- **UV Index:** 0.0\n- **Daylight:** No (its currently dark)\n\nIt seems to be quite cold with a significant wind chill factor.\n[openai/gpt-4o-mini: 2 calls, tokens: 162 -&gt; 144, 0.02 cents, time: 3.81s tc: 0.02 c, ctx: 306]\n[Weather Agent]&gt; \n</code></pre> <p>That's it. We've created an agent, powered by the GPT-4o-mini LLM, and given it a tool which it can use to retrieve weather reports. (The weather info is provided by https://open-meteo.com.)</p> <p>Try running some of the other example agents to get a feel for the framework.</p> <p>Try <code>examples/database_agent.py</code> for a basic Text-to-SQL agent.</p>"},{"location":"#understanding-agents","title":"Understanding Agents","text":"<p>Agentic agents by default use the LLM ReAct pattern. This means:</p> <ul> <li>The LLM controls the execution flow of your agent</li> <li>You specify the tasks and flow of your agent via the LLM system prompt</li> <li>The agent gets one or more tools that it can use to accomplish its task</li> <li>The agent runs in this loop until it decides that it can't go further:<ul> <li>plan next step</li> <li>generate text completion or tool call     (platform executes tool call)</li> <li>observe tool call results</li> </ul> </li> </ul>"},{"location":"#components-of-an-agent","title":"Components of an agent","text":"<p>An agent is defined by its behavior - what is does as perceived from the outside. But inside each agent has these properties:</p> <ul> <li>name</li> <li>instructions</li> <li>list of tools</li> <li>list of children agents</li> <li>chosen LLM model</li> <li>a 'welcome' message explaining the purpose of the agent</li> </ul> <p>Notice that agents can call both <code>tools</code>, which are regular code functions, or other agents, in the same way. </p> <p>Calling \"sub agents\" allows us to organize a set of multiple agents to solve a single problem. The simplest example looks like this:</p> <pre><code>from agentic.tools import GoogleNewsTool\n\nproducer = Agent(\n    name=\"Producer\",\n    welcome=\"I am the news producer. Tell me the topic, and I'll get the news from my reporter.\",\n    instructions=\"You are a news producer. Call the reporter with the indicated topic.\",\n    model=\"gpt-4o-mini\",\n    tools=[\n        Agent(\n            name=\"News Reporter\",\n            instructions=f\"\"\"\n        Call Google News to get headlines on the indicated news topic.\n        \"\"\",\n            tools=[GoogleNewsTool()],\n        )\n    ],\n)\n</code></pre>"},{"location":"#calling-agents-in-sequence","title":"Calling agents in sequence","text":"<p>Treating agents as a <code>subroutine</code> is useful, but sometimes we want <code>pipeline</code> semantics where we want to invoke the next agent by \"handing off\" execution to that agent and not waiting for it to return. We can just use the <code>handoff</code> property to do so:</p> <pre><code>from agentic import handoff\n\nagentA = Agent(\n    name=\"Producer\",\n    welcome=\"This is the handoff demo.\",\n    instructions=\"Print the message 'I am A', then call agent B. Afterwards print 'WARNING!'\",\n    tools=[\n        handoff(Agent(\n            name=\"Agent B\",\n            instructions=\"Print the msssage 'and I am B'\",\n        ))\n    ],\n)\n\npython examples/handoff_demo.py\nThis is the handoff demo.\n&gt; run\nI am A\nand I am B\n&gt; \n</code></pre> <p>Without using <code>handoff</code> we would have seen the WARNING message printed from the root agent. Handoff can be useful if your sub-agent generates a lot of output, because normally that output when be fed back into AgentA as the <code>observation</code> step, which means both another inference call to pay for, and means that AgentA may summarize or alter the results.</p>"},{"location":"#the-problem-with-function-calling","title":"The problem with function calling","text":"<p>Since the introduction of \"function calling\" by OpenAI, most frameworks have built around the idea of agent \"tools\" as functions. Many have extended this idea to include calling agents calling other agents as tools. </p> <p>The problem is that function calling generally assumes synchronous semantics and strictly  typed parameters and return values. Both of these make poor assumptions when dealing with AI agents. Since agents can easily be long-running, it is much better assume an event-driven model (sending messages, and waiting for events) than a synchronous one. Strict typing is useful in compiled code, but LLMs are really best with text and language, not strict compiler types.</p> <p>As you start building more complex agents, you want them to run longer, be decomposable into multiple units, and have flexible behavior like stopping for human input. Agentic is designed to make these more complex use cases easy.</p>"},{"location":"#tools-as-agents","title":"Tools as Agents","text":"<p>Agentic assumes an event driven model for agents. We send events to agents when we want them to do something, and the agent publishes events back to us with the results. Because event driven is so key, tool calling is also event driven. Although the framework hides most of the details, every tool (function) call happens asynchronously. One of the implications of this design is that tools can \"interrupt\" the agent, and wait for human input. When your agent is waiting for input it is effectively paused, consuming no resources. This means that complex patterns like \"send an email for clarification, and wait for the reply\" are easy and low-cost to build.</p>"},{"location":"#complete-example","title":"Complete example","text":"<pre><code>from agentic import Agent, AgentRunner\nfrom agentic.tools import LinkedinTool, HumanInterruptTool\n\nresearcher = Agent(\n    name=\"Person Researcher\",\n    welcome=\"I am your People Researcher. Who would you like to know more about?\",\n    instructions=\"\"\"\nYou do research on people. Given a name and a company:\n1. Search for matching profiles on linkedin.\n2. If you find a single strong match, then prepare a background report on that person. Make sure\nto print the full report.\n3. If you find multiple matches, then ask stop and ask the user for clarification. Then go back to step 1.\nIf you are missing info, then seek clarification from the user.\n\"\"\",\n    model=\"openai://gpt-4o-mini\",\n    tools=[\n        LinkedinTool(), \n        HumanInterruptTool(),\n        Agent(\n            name = \"Person Report Writer\",\n            instructions=\"\"\"\n        You will receive the URL to a linkedin profile. Retrieve the profile and\n        write a background report on the person, focusing on their career progression\n        and current role.\n            \"\"\",\n            tools=[LinkedinTool()],\n            model=\"anthropic://claude-sonnet-3.5\",\n        )\n    ]\n)\n\nrunner = AgentRunner(agent)\nrunner.repl_loop()\n</code></pre> <p>Breaking down our example</p> <p>First we define our top-level agent, the \"Person Researcher\", give it a goal and a task list, an LLM model, and some tools:</p> <ul> <li>A linkedin tool for searching for linkedin profiles</li> <li>A \"Human interrupt\" tool which the agent can call to ask for human help</li> </ul> <p>Now, we define a \"sub agent\" for this agent to use as another tool. This is the \"Person Report Writer\" agent, with its own instruction and a  different LLM model. We include this agent in the list of tools for the Researcher.</p> <p>Running our agent</p> <p>To run our agent, we construct an <code>AgentRunner</code>. This object manages a single multi-turn session interacting with our agent.</p> <p>Here is the complete (condensed) run output:</p> <pre><code>(agentic) scottp@MacBook-Air agentic % python examples/people_researcher.py \nI am the People Researcher. Tell me who you want to know about.\n&gt; marc benioff\n--&gt; search_profiles({\"name\":\"marc benioff\"})\n--&gt; get_human_input({\"request_message\":\"I found multiple profiles for Marc...\"})\nI found multiple LinkedIn profiles for Marc Benioff. Here are the details:\n\n1. **Marc Benioff**  \n   - **Headline:** Chair &amp; CEO at Salesforce  \n   ...\n\n2. **Marc Benioff**  \n   - **Headline:** Bachelor's degree at Brunel University London  \n   ...\n...\nPlease let me know which profile you would like to know more about. \n&gt; 1\ncall_person_report_writer({\"message\":\"Please prepare a background report on Marc Benioff...\"})\n--&gt; get_profile({\"url\":\"https://www.linkedin.com/in/marcbenioff\"})\n### Background Report on Marc Benioff\n**Current Role:**\nMarc Benioff is the Chair and CEO of Salesforce, a leading cloud-based software company headquartered in San Francisco, California. Under his leadership, Salesforce has become a pioneer in customer relationship management (CRM) software and has significantly influenced the tech industry with its innovative solutions and commitment to social responsibility.\n\n**Career Progression:**\n- **Early Career:** Marc Benioff began his career at Oracle Corporation, where he worked for 13 years. During his time at Oracle, he held various positions, gaining valuable experience in software development and sales.\n...\n</code></pre> <p>We call <code>start</code> to start our agent. Now we iteratively grab events from the agent until the turn is finished.</p> <ul> <li>The initial user prompt is passed to our Researcher agent. It considers its instructions and the user input. Based on this it generates  a tool call to <code>LinkedinTool.search_profiles</code>. </li> <li>The <code>search_profiles</code> function is called, and the result is returned to the agent, which \"observes\" this result and generates the next event (the \"observation\" event.)</li> <li>The agent \"loops\" and determines that multiple profiles were returned, so it prints the list (emits output events with the text), and then creates a tool call to <code>get_human_input</code>.</li> <li>The runner returns the interrupt event, return True from <code>event.requests_input()</code> to be the agent request. We print that request message, collect input from the user, and then call <code>continue_with</code> on the runner with the response. The human response will be returned as the value of the <code>get_human_input</code> tool call.</li> <li>On <code>runner.next</code> the agent considers that we specified to check the first returned profile, so it generates a tool call to <code>call_person_report_writer</code> to create the report. If the user had responded \"I don't know\", then the agent could decide it can't go any further and just finish the turn.</li> <li>The <code>call_person_report_writer</code> function now activates our \"Person Report Writer\" agent, with the profile URL as input, but in a new LLM context. This agent calls <code>get_profile</code> to get the full Linkedin profile, then writes the research report.</li> <li>Finally the report is returned to the parent agent, which prints the results.</li> </ul>"},{"location":"#things-to-note","title":"Things to note","text":"<p>We have used the convenience <code>repl_loop</code> in <code>AgentRunner</code> to interface to our agent. But we can write our own loop (or API or whatever) to run our agent:</p> <pre><code>runner.start(command)\nfor event in self.next_turn(request: str):\n    print(\"Agent event: \", event)\n</code></pre> <p>The <code>next_turn</code> function will keep emitting events until the current turn of the agent is complete. Because you are getting fine-grained events as the agent runs, you can choose to do other things in the middle, including things like modifying the agent by giving it more tools. Even though this interface looks like the agent is \"running\" some thread (like in Langchain), in fact the agent runs step by step, generating events along the way, but it can stop at any time.</p> <p>Events have a <code>depth</code> attribute which indicates how deep is the agent that is generating the event. So the top agent generates <code>depth=0</code>, the first level  sub-agent generates at <code>depth=1</code> and so forth. </p> <p>The list of tools on an agent should be modifiable at any time:</p> <pre><code>agent.add_tool(tool)\nagent.remove_tool(tool)\n</code></pre> <p>However, tools probably shouldn't modify the running agent directly. Safer that they publish events like <code>EnableTool</code> which can be handled properly by the framework (there might be security controls or what not).</p> <p>RunContext</p> <p>The state for your agent is kept and transmitted between turns via the <code>RunContext</code> object. One is created each time a turn starts.</p>"},{"location":"#examples","title":"Examples","text":"<p>Read Examples or look at the github repo examples folder.</p>"},{"location":"#try-the-web-ui-using-streamlit","title":"Try the web UI (using streamlit)","text":"<pre><code>agentic ui\n</code></pre>"},{"location":"AGENTIC_MANIFESTO/","title":"Agentic Design Principles","text":""},{"location":"AGENTIC_MANIFESTO/#1-an-agentic-system-should-leverage-the-llm-as-much-as-possible","title":"1. An agentic system should leverage the LLM as much as possible.","text":"<p>As much as possible an agentic app leverages the planning and reasoning of the LLM. Most logic should happen at inference-time rather than compile-time.</p>"},{"location":"AGENTIC_MANIFESTO/#2-the-probabilistic-nature-of-llm-inference-is-a-feature","title":"2. The probabilistic nature of LLM inference is a feature","text":"<p>Traditional software strives for perfectly deterministic behavior. But the probabilitic nature of the LLM gives us the ability to write software which is creative, reflective and self-improving. Many systems will need guardrails and self-healing logic to ensure reliable operation, but trying to get perfect determinism from an agent is misguided.</p>"},{"location":"AGENTIC_MANIFESTO/#3-agents-follow-the-actor-model","title":"3. Agents follow the actor model","text":"<p>Agents should follow the actor model from computer science, which means: - They are encapsulated programs which can only manipulate their own private state - They are event driven, responding to messages and generating messages</p>"},{"location":"AGENTIC_MANIFESTO/#4-tools-as-agents","title":"4. Tools as agents","text":"<p>It is common to want to apply function calling semantics to LLM programs, which is encouraged by OpenAI's function calling API. But function calling is the wrong paradigm for agents since it generally implies synchronous execution and strictly typed parameters. Both of these are poor assumptions when building AI agents.</p> <p>Rather than generalize everything as a function call, it is better to generalize everything as an actor (agent). So doing a \"web search\" call means sending a message event to the \"web search agent\", which will reply with events containing the results. We can easily implement this as a compile-time tool, but it also means that our \"web search tool\" could just as easily be another full agent.</p>"},{"location":"AGENTIC_MANIFESTO/#5-the-best-tool-protocols-are-languages","title":"5. The best tool protocols are languages","text":"<p>LLMs are really good at language, which implies that the best way to interface them into traditional systems is via some protocol language, rather than describing some huge set of REST endpoints. Wherever possible try to build tools on top of language protocols like SQL or GraphQL, where the LLM can express complex operations very efficiently. If your system doesn't support a language already known to your model, you can define a new language and teach it to your agent. </p>"},{"location":"AGENTIC_MANIFESTO/#agent-trust","title":"Agent Trust","text":""},{"location":"AGENTIC_MANIFESTO/#6-an-agent-must-be-trusted-by-humans-or-it-will-have-no-value","title":"6. An agent must be trusted by humans, or it will have no value","text":"<p>AI agents will not, and should not, be trusted by default. They have to earn trust. These guidelines are a starting point for building trustworthy agents. The key elements of trust include:     - the agent will only perform expected operations     - the behavior of the agent is explainable     - the agent will rely only on knowledge we expect it to use, and it will         explain its knowledge sources when it makes a decision     - the agent stays aligned with its operator's values, and the values of         human safety</p>"},{"location":"AGENTIC_MANIFESTO/#7-agents-must-only-run-under-the-authority-of-a-named-human-user","title":"7. Agents must only run under the authority of a named human user","text":"<p>Agents always inherit their authority to access information or resources from their human creators and operators.  Agents must never run autonomously  without any human being named as responsible for their operation.  Allowing anonymous (or \"AI identity\") operation is a dangerous anti-pattern. </p> <p>Human in the loop is a key feature that agents should rely on until they can prove that they can operate autonomously.</p>"},{"location":"AGENTIC_MANIFESTO/#8-agent-behavior-must-be-explainable","title":"8. Agent behavior must be explainable","text":"<p>We cannot necessarily predict agent behavior, but agentic systems must explain what they are doing and why as much as possible. Unexplainable behavior is a system bug to be fixed, and should not be tolerated. Part of explainability is transparency about the operations executed and resources used by the agent.</p> <p>Agent User Interface should always promote and provide explainability - they should never hide the actions of the agent.</p>"},{"location":"AGENTIC_MANIFESTO/#9-agents-should-come-with-test-contracts","title":"9. Agents should come with test contracts","text":"<p>Test Contracts are a way of automatically testing for the correct behavior of your agent. These are critical to building reliable agentic systems, especially ones that run</p>"},{"location":"AGENT_MEMORY/","title":"Agent Memory","text":"<p>Agents support multiple types of memory:</p> <ul> <li>Short term memory in \"run history\" (the chat session) of the agent. Run history consumes much of the LLM context that the LLM operates on. Agents include this memory type by default.</li> </ul> <p>You can clear your agent's short term memory:</p> <p><code>runner.reset_session()</code></p> <ul> <li>Persistent facts. Facts and data can be stored anywhere, and applied to the agent context when it runs. Agents expose a <code>memories</code> attribute to make loading memories easy:</li> </ul> <pre><code>uploader = Agent(\n    name=\"TransistorFM\",\n    memories=[\"Default show ID is 60214\"],\n)\n</code></pre> <p>but you can also use a <code>ContextManager</code> to inject information into the agent context.</p> <ul> <li> <p>Run history. Agents can persist their \"run histories\" (chat sessions) so that those runs can be reviewed later.</p> </li> <li> <p>Larger-than-context memory. There are multiple systems for storing memories for your agent that exceed the context window limits. The most popular is RAG - retrieval augmented generation. This system allows your agent to store lots and lots of data and intelligently \"retrieve\" only part of it to help it answer (\"generate\") a question.</p> </li> </ul>"},{"location":"Building_Agents/","title":"Building and running agents","text":""},{"location":"Building_Agents/#terminology","title":"Terminology","text":"<p>An \"agent\" is an LLM-powered program that is defined in code. </p> <p>The persistent history of your interactions with an agent consitute a run. The LLM context is preserved as long as the run session continues. Once a new Run is started then the context goes back to the initial state.</p> <p>Each interaction of: user request -&gt; agent thinking -&gt; agent response is called a turn. A single run can include many turns. </p> <p>As your agent operates, it may take multiple steps in order to complete a turn. Generally each step will result in either a completion - the generation of some text, or a function call, or both together. Tracing the steps of your agent inside of a turn is done by reviewing the logs generated by the agent.</p> <p>Construct an Agent like this:</p> <pre><code>from agentic.common import Agent\n\ndef weather_tool():\n    return \"The weather is nice today.\"\n\n\nagent = Agent(\n    name=\"Basic Agent\",\n    welcome=\"I am a simple agent here to help answer your weather questions.\",\n    instructions=\"You are a helpful assistant.\",\n    model=\"openai/gpt-4o-mini\",\n    tools=[WeatherTool()],\n)\n</code></pre> <p>The <code>instructions</code> set the \"system prompt\" for the LLM. The \"welcome message\" is just a string that can be displayed to the end user to help them use the agent.</p> <p>Optional parameters to your agent include:</p> <pre><code>max_tokens - The maximum number of tokens to generate on each completion\nmemories - A list of facts to inject into the Agent's context for every Run\n</code></pre> <p>See models for information on using different models. </p> <p>See tools for information on creating and using tools.</p>"},{"location":"Building_Agents/#settings-and-secrets","title":"Settings and Secrets","text":"<p>When your agent runs it will likely need api keys for various services. You can set these keys in your environment, but this approach gets very unwieldy with lots of keys.</p> <p>Agentic includes a simple system for managing <code>settings</code> and <code>secrets</code>. Both are stored in a local SQLite database file (inside <code>~/.agentic</code>), but the secrets are encrypted.</p> <pre><code>agentic list            - list your settings\nagentic list-secrets    - list your secrets\n\nagentic set &lt;setting&gt; &lt;value&gt; \nagentic get &lt;setting&gt;\n\nagentic set-secret &lt;secret name&gt; &lt;value&gt;\nagentic get-secret &lt;secret name&gt;\n</code></pre> <p>All settings and secrets are automatically injected into the environment when your agent runs, but it is recommended to get values from the <code>RunContext</code> using <code>get_config</code> and <code>get_secret</code>. One nice feature is that secrets can be stored in a <code>namespace</code> named after your agent, so that you can manage multiple values across different agents.</p>"},{"location":"Building_Agents/#using-agentrunner-and-the-repl","title":"Using AgentRunner and the REPL","text":"<p>The <code>AgentRunner</code> class is a convenience utility for running a repl to interact with your agent:</p> <pre><code>from agentic.common import Agent, AgentRunner\n\nagent = Agent(...)\n\nif __name__ == 'main':\n    AgentRunner(agent).run_repl()\n</code></pre> <p>By default it maintains a persistent Run (session) with your agent, so that each turn is appending to the active run. </p> <pre><code>% python examples/basic_agent.py \nI am a simple agent here to help answer your weather questions.\npress &lt;enter&gt; to quit\n[Basic Agent]&gt; my name is scott\nHello, Scott! How can I assist you today?\n[Basic Agent]&gt; what is my name ?\nYour name is Scott.\n[openai/gpt-4o-mini: 1 calls, tokens: 12 -&gt; 5, 0.00 cents, time: 0.73s tc: 0.00 c, ctx: 40]\n</code></pre> <p>The runner repl includes a set of \"dot\" system commands:</p> <pre><code>&gt; .help\n\n    .agent - Show the state of the active agent\n    .run &lt;agent name&gt; - switch the active agent\n    .history - show the history of the current session\n    .debug [&lt;level&gt;] - enable debug. Defaults to 'tools', or one of 'llm', 'tools', 'all', 'off'\n    .settings - show the current config settings\n    .model - switch the active LLM model\n    .help - Show this help\n    .quit - Quit the REPL\n</code></pre> <p>Examples:</p> <pre><code>[Basic Agent]&gt; .agent\nBasic Agent\nYou are a helpful assistant.\ntools:\n  WeatherTool\n</code></pre> <p>The .debug command is especially helpful to activate different kinds of tracing:</p> <pre><code>.debug tools    - Shows logging for tool start/finish events\n.debug llm      - Shows all LLM completion calls\n.debug agents   - Only log events where an agent starts a turn\n.debug all      - Logs everything\n</code></pre> <p>We often run with <code>.debug tools</code> to track what our agents are doing.</p>"},{"location":"Building_Agents/#things-to-note","title":"Things to note","text":"<p>We have used the convenience <code>repl_loop</code> in <code>AgentRunner</code> to interface to our agent. But we can write our own loop (or API or whatever) to run our agent:</p> <pre><code>runner = AgentRunner(agent)\nwhile True:\n    request = input(\"prompt&gt; \")\n    for event in runner.next_turn(request):\n        print(\"Agent event: \", event)\n</code></pre> <p>The <code>next_turn</code> function will keep emitting events until the current turn of the agent is complete. We can loop again and let the user request another task from the agent.</p> <p>Because you are getting fine-grained events as the agent runs, you can choose to do other things in the middle, including things like modifying the agent by giving it more tools. Even though this interface looks like the agent is \"running\" some thread (like in Langchain), in fact the agent runs step by step, generating events along the way, but it can stop at any time.</p> <p>See more about events.</p>"},{"location":"Building_Agents/#agentic-cli","title":"Agentic CLI","text":"<p>Commands:</p> <pre><code>--help          - Get help\n\nmodels          - list some popular LLM models\nlist            - List all settings.\nset             - Set a config value.\nget             - Get a config value.\ndelete          - Delete a config value.\n\nlist-secrets    List all secrets.\nset-secret      Set a secret.\nget-secret      Get a secret.\ndelete-secret   Delete a secret.\n\nollama          - List the latest popular models from Ollama. Use \"ollama pull &lt;model&gt; to download.\nui              - Runs the agentic UI\nclaude          - Runs a completion with Anthropic's Claude sonnet model\ngpt             - Runs a completion with OpenAI's GPT-4o-mini model. Use --model to override.\n</code></pre>"},{"location":"Debugging/","title":"Debugging agents","text":"<p>The simplest tools for debugging are using the debug levels in the REPL:</p> <pre><code>'agents' - Log agent operations\n'tools'  - Log all tool calls\n'llm'    - Log LLM completions\n'all'    - Log everything\n</code></pre> <p>Note that you can also combine tags like 'tools,llm':</p> <pre><code>&gt; .debug tools,llm\nDebug level set to: tools,llm\n</code></pre> <p>Switching models</p> <p>Use <code>.model &lt;model&gt;</code> to temporarily change the active model of the current agent:</p> <pre><code>[Basic Agent]&gt; .model claude-3-opus-20240229\nModel set to claude-3-opus-20240229\n[Basic Agent]&gt; when is your training ?\n&lt;thinking&gt;\nThe user is asking when my training occurred. This question does not require any of the provided weather-related tools to answer. The tools are for retrieving current weather, weather forecasts, historical weather data, and historical weather averages for specific locations and dates. None of them are relevant for providing information about my own training.\n&lt;/thinking&gt;\n\nI do not have specific information about when I was trained. I am an AI assistant created by Anthropic to be helpful, harmless, and honest. The details of my training process are not something I have direct knowledge of.\n[claude-3-opus-20240229: 1 calls, tokens: 12 -&gt; 113, 2.98 cents, time: 5.17s tc: 2.98 c, ctx: 125]\n</code></pre> <p>Showing chat messages</p> <p>Use <code>.history</code> to see the list of Messages in the current LLM context.</p>"},{"location":"Events/","title":"Event system","text":"<p>Events have a <code>depth</code> attribute which indicates how deep is the agent that is generating the event. So the top agent generates <code>depth=0</code>, the first level  sub-agent generates at <code>depth=1</code> and so forth. </p> <p>Agents publish events whenever they are asked to do something. For a single agent this mechanism is simple:</p> <pre><code>caller      --- msg --&gt;     agent\n  |                           |\n  |         &lt;-- event ---     |\n</code></pre> <p>However, once agents start calling other agents, it gets more complicated. Our general rules is that ALL events published at any level should bubble up back to the original caller. This is to maximize the caller's visibility into what the system is doing:</p> <pre><code>caller      --- msg --&gt;     agent A               agent B\n  |                           |                       |\n  |         &lt;-- event1 ---    |                       |\n  |                           |    --- call B -&gt;      |\n  |                           |                       |\n  |                           |     &lt;-- event 2 --    |\n  |         &lt;-- event 2 ---   |                       |\n</code></pre> <p>Each event has an agent <code>name</code> property, and <code>depth</code> property which indicates how far down  in the call tree the event originated.</p> <p>So the caller will get these two events:</p> <pre><code>event1 (Agent A, depth=0)\nevent2 (Agent B, depth=1)\n</code></pre> <p>This allows the caller to ignore sub-agent execution if it prefers.</p>"},{"location":"Events/#agent-execution-flow","title":"Agent execution flow","text":"<p>When you call agent A, it may execute agent B, plus agent C, and they in turn may call other agents.</p> <p>If you want to observe all events from the entire execution tree, then you should implement logic to record the recept of events from each distinct agent, and then make sure to wait for the <code>TurnEnd</code> message from each one. </p>"},{"location":"Events/#agent-pipeline","title":"Agent pipeline","text":"<p>To implement \"pipeline semantics\", agents can \"hand off\" from one to another. In this case the sub-agent will assume the original caller of the first agent, and will assume its <code>depth</code> as well:</p> <pre><code>caller      --- msg --&gt;     agent A               agent B\n  |                           |                       |\n  |         &lt;-- event1 ---    |                       |\n  |                           |  ---  *handoff* B -&gt;  |\n  |         &lt;-- turnend: A -- |                       |                \n  |                                                   |\n  |         &lt;-- ---------------------- event 2 --     |\n</code></pre> <p>So the caller will get events like this:</p> <pre><code>event1 (Agent A, depth=0)\nevent2 (Agent B, depth=0)\n</code></pre>"},{"location":"Events/#chat-history","title":"Chat history","text":"<p>A typical interactive agent is built with chat history which maintains the history of interactions over the life of a session.</p>"},{"location":"Flows/","title":"ReAct Agent","text":"<p>This is the default form for Agentic agents.</p>"},{"location":"Flows/#pipeline","title":"Pipeline","text":"<p>A pipeline strings together the outputs-&gt;inputs of a set of agents in a linear sequence.</p> <pre><code>from agentic import Agent, Pipeline\n\npipeline = Pipeline(\n    Agent(name=\"agent 1\"),\n    Agent(name=\"agent 2\"),\n    Agent(name=\"agent 3\"),\n)\n\nAgentRunner(pipeline).run()\n</code></pre>"},{"location":"Internals/","title":"Agent processing flow","text":"<p>Forward direction processing happens by sending events to agent, which may send events to sub-agents, and those agents emit events back with results.</p>"},{"location":"Internals/#special-tool-results","title":"Special tool results:","text":"<p><code>PauseForChildResult</code>  - Put the agent in a paused state, and wait for <code>TurnEnd</code> to come back from a sub-agent call. Assumes the event has already been sent to the child.</p> <p><code>PauseForInputResult</code>  - Put the agent in a paused state, and emit a <code>WaitForInput</code> event back to the caller. Wait for the <code>ResumeWithInput</code> event to come back from the caller.</p> <p><code>FinishAgentResult</code> - Special result to indicate that we have sent a handoff Prompt to the next agent, and this agent can finish execution (without sending TurnEnd).</p> <p>When Agent A calls Agent B, it sends a <code>Prompt</code> message and then enters a \"pause\" state (by having the sub-agent tool call return <code>PauseForChildResult</code>).</p> <p>The pause state is mid-way through an LLM function call. When the <code>TurnEnd</code> event is  received from agent B then Agent A can resume by processing the result as the result of the tool call.</p> <p>When Agent A wants to \"pause for human\", then it needs makes a local tool call which returns a <code>PauseForInputResult</code> result. This puts the agent in a paused state and its emits a <code>WaitForInput</code> event back to the caller.  The caller should collect input and send a <code>ResumeWithInput</code> back to agent A. Agent A handles this event by re-calling the tool function with the human input. The tool function can process or return the value as is. Agent A then processes this as the result of the original tool call.</p> <p>So Agent A can be paused waiting on upstream or downstream, but resuming processing looks the same: treat the result as the result of a function call and continue processing.</p>"},{"location":"Internals/#handoff","title":"Handoff","text":"<p>Handoff is when agent A calls agent B, but then \"hands off\" its turn to Agent B. Agent A stops processing. Agent B assumes current context, the original caller, the original depth, and is expected to emit the <code>TurnEnd</code> event back to the original caller. It should also emit the </p>"},{"location":"Internals/#case-1-normal-sub-agent-call-with-pauseforchildresult","title":"Case 1: Normal Sub-Agent Call with PauseForChildResult","text":"<pre><code>%% Case 1: Normal Sub-Agent Call with PauseForChildResult\nsequenceDiagram\n    participant caller\n    participant Agent A\n    participant Agent B\n\n    caller-&gt;&gt;Agent A: Event\n    Note over Agent A: Process Event\n    Agent A-&gt;&gt;Agent B: Prompt\n    Note over Agent A: Return PauseForChildResult\n    Note over Agent A: Enter Paused State\n    Agent B-&gt;&gt;Agent A: TurnEnd\n    Note over Agent A: Resume Processing\n    Agent A-&gt;&gt;caller: TurnEnd\n</code></pre>"},{"location":"Internals/#case-2-pause-for-human-input","title":"Case 2: Pause for Human Input","text":"<pre><code>%% Case 2: Pause for Human Input\nsequenceDiagram\n    participant human\n    participant caller\n    participant Agent A\n\n    caller-&gt;&gt;Agent A: Event\n    Note over Agent A: Process Event\n    Note over Agent A: Tool returns PauseForInputResult\n    Agent A-&gt;&gt;caller: WaitForInput\n    caller-&gt;&gt;human: Request Input\n    human-&gt;&gt;caller: Provide Input\n    caller-&gt;&gt;Agent A: ResumeWithInput\n    Note over Agent A: Re-call tool with input\n    Note over Agent A: Continue Processing\n    Agent A-&gt;&gt;caller: TurnEnd\n</code></pre>"},{"location":"Internals/#case-3-handoff-to-another-agent","title":"Case 3: Handoff to Another Agent","text":"<pre><code>%% Case 3: Handoff to Another Agent\nsequenceDiagram\n    participant caller\n    participant Agent A\n    participant Agent B\n\n    caller-&gt;&gt;Agent A: Event\n    Note over Agent A: Process Event\n    Agent A-&gt;&gt;Agent B: Prompt\n    Note over Agent A: Return FinishAgentResult\n    Note over Agent A: Stop Processing\n    Note over Agent B: Assume Context &amp; Depth\n    Agent B-&gt;&gt;caller: TurnEnd\n</code></pre>"},{"location":"Internals/#ray-actor-logic","title":"Ray Actor logic","text":"<p>Each running agent is execute by a remote Ray object. This means that we call its methods via Ray and they return Promises to get their results. We have to call <code>ray.get</code> to retrieve or wait for the actual result.</p> <p>Our basic agent execution loop looks like:</p> <pre><code>user input -&gt;\n    remote_gen = agent.receiveMessage.remote(Prompt())\n        (agent starts the LLM \"turn\" loop, calling LLM completions and yielding events)\n    for next_ref in remote_gen:\n        event = ray.get(next_ref)  # Prompt handling yields events until turn is over\n</code></pre> <p>If our agent needs to call another agent, it creates the Agent and calls it via Ray remote:</p> <pre><code>user input -&gt;\n    remote_gen = \n        (agent starts the LLM \"turn\" loop, calling LLM completions and yielding events)\n    for next_ref in agent.receiveMessage.remote(Prompt()):\n            # Agent does a function call to a child. \n            agent -&gt; starts sub_agent\n                agent -&gt; iterate over Prompt\n                    sub_agent yield Event\n                agent yield Event\n        event = ray.get(next_ref)  # Prompt handling yields events until turn is over\n</code></pre> <p>If the child call is a <code>handoff</code> then the parent agent simply gives the child agent the same <code>depth</code>, and once the child is done then the parent agent finishes without generating the <code>TurnEnd</code> event, since the child already did.</p>"},{"location":"Internals/#pause-and-resume","title":"Pause and Resume","text":"<p>To support \"human in the loop\", the agent can \"pause\" execution by saving its state, yielding a <code>WaitForInput</code> event, then returning from its loop. Now the caller should send the <code>ResumeWithInput</code> event to the agent which will continue executing from where it left off.</p> <p>If a sub agent needs to Pause, then it emits the WaitForInput event, and all parent agents pause and re-yield that event. They save their context of the child call and restore it when the Resume event is received.</p>"},{"location":"Models/","title":"Models","text":"<p>Agentic uses Litellm as the \"LLM router\" which allows us to support most popular LLMs via simple configuration.</p> <p>Models providers supported include:</p> <ul> <li>OpenAI</li> <li>Anthropic</li> <li>Google</li> <li>Llama3.x</li> <li>Deepseek</li> </ul> <p>and many more.</p> <p>When you specify the <code>model</code> parameter to your Agent, supply a qualified model name like:</p> <pre><code>openai/gpt-4o\n</code></pre> <p>or </p> <pre><code>anthropic/claude-3-5-sonnet-20240620\n</code></pre> <p>Try using <code>agentic models</code> at the command line to get a list of popular models.</p>"},{"location":"Models/#ollama","title":"Ollama","text":"<p>Agentic has built-in support for using locally installed models via Ollama.</p> <p>To use, first install ollama. Then serve your model:</p> <pre><code>ollama run llama3.2:latest\n</code></pre> <p>And specify your agent's model:</p> <pre><code>model=ollama/llama3.2:latest\n</code></pre>"},{"location":"PROJECT_STRUCTURE/","title":"Project structure","text":"<p>An Agentic project has the following structure:</p> <pre><code>&lt;root&gt;/\n    pyproject.toml\n    agents/\n        agent1.py\n        agent1.prompts.yaml\n        agent2.py\n    tools/\n        weather_tool.py\n        news_tool.py\n        tests/\n            test_weather_tool.py\n            test_news_tool.py\n    indexes/\n        personal.rag.sqlite\n        dev.rag.sqlite\n    evals/\n        agent1.eval\n        agent2.eval\n</code></pre>"},{"location":"REST_API/","title":"REST API","text":"<p>Agentic includes built-in support for your agent to expose a REST API using FastAPI. This API is an alternative way to use your agent besides the command line.</p> <p>To start the API server, using the <code>serve</code> method on <code>AgentRunner</code>:</p> <pre><code>AgentRunner(agent).serve()\n</code></pre> <p>Note that you will need to add some idle loop to prevent your program from existing. For convenience you can start the API server with the CLI:</p> <pre><code>agentic serve examples/basic_agent.py\n</code></pre> <p>that you can use to interact with it programmatically. The AgentRunner runs a FastAPI service that exposes an interface to your agent.</p> <p>Your agent will expose endpoints at:</p> <pre><code>http://0.0.0.0:8086/&lt;name of agent&gt;\n</code></pre> <p>like:</p> <pre><code>http://0.0.0.0:8086/basic_agent\n</code></pre> <p>visit the embedded <code>/docs</code> page for quick testing:</p> <pre><code>http://0.0.0.0:8086/basic_agent/docs\n</code></pre> <p>Some of the main endpoints include:</p> <pre><code>GET /describe           Get the agent spec\nPOST /process           Start a request\nGET /getevents          SSE stream events from a request\nGET /stream_request     Process and stream events in one call\n</code></pre>"},{"location":"Settings/","title":"Settings","text":"<p>AGENTIC_DEBUG=agents,tools,llm,all</p> <p>AGENTIC_OVERRIDE_MODEL=xx</p>"},{"location":"Tools/","title":"Tools","text":"<p>Tools are the fundamental way that your agent gets access to the world around it. Tools can literally do anything - query any data or take any action - that you can think of.</p> <p>It is tempting to think of tools the way we think about libraries that we use in traditional code, but this is a mistake. In fact tools are the key component in the AI to computer interface.  They determine how well the LLM can interact with the world, and the fidelity with which your agent can perceive the world around it. Tools have a huge impact on the efficacy of agents, and building agents often involves a lot of time working on tools (although we are getting better \"off the shelf\" tools all the time.)</p> <p>At root, tools are exposing functions to your Agent. Using the tool calling protocol developed by OpenAI, your agent elects to call tools by generating a text block in its output, and this output is parsed by the framework and turned into the actual function call.</p> <p>Side node: The smolagents library from Huggingface promotes the idea of using  CodeAgents instead of tool calling. Some researchers have found that having your agent write code - on demand - to call functions elicits superior results than traditional tool calling. It's certainly an intriguing notion, and one that we are testing presently.</p> <p>Agentic supports providing tool functions as:</p> <ul> <li>Simple functions</li> <li>Class instance methods</li> <li>Langchain tools</li> <li>Model Context Protocol (from Anthropic) tools</li> </ul> <p>Here are a few examples:</p> <pre><code>def simple_function(arg1: int, arg2: int) -&gt;:\n    \"\"\" Multiplies two numbers by a mystery factor \"\"\"\n\n    return arg1 * arg2 * 23\n\nclass FileReaderTool:\n    def get_tools(self) -&gt; list[Callable]:\n        return [\n            self.read_file,\n            self.write_file,\n        ]\n\n    def read_file(self, path: str) -&gt; str:\n        \"\"\" Returns the file at the given path \"\"\"\n        return open(path).read()\n\n    def write_file(self, path: str, content: str) -&gt; str:\n        \"\"\" Writes the provided content to the indicated path \"\"\"\n        with open(path, \"w\") as f:\n            f.write(content)\n        return \"The file was written\"\n\nagent = Agent(\n    ...\n    tools = [simple_function, FileReaderTool()]\n)\n</code></pre> <p>Note that the docstring is required to describe each function.</p> <p>Here are some rules/guidelines for writing good tools:</p> <ul> <li>Generally we find classes and methods are a more useful form than bare functions. There aren't a lot of bare functions that are super helpful tools.</li> <li>Using classes and methods means that you can keep state in your tool (via <code>self</code>) and share it between function calls.</li> <li>The name of the function, the docstring, and the parameter names are all passed to the LLM. Function names should very clearly explain the purpose of the function.</li> <li>You can describe parameter usage (possible values, etc...) in the docstring, but often its enough to just have good parameter names.</li> <li>Try to avoid super generic function names like <code>read_file</code>, and consider prefixing  functions with a namespace, like <code>github_read_file</code>.</li> </ul> <p>Although you can always use \"plain functions\" for tools, Agentic has some special support for particular tool patterns.</p> <p>RunContext</p> <p>When your agent is started, a <code>RunContext</code> object is created and preserved through the lifetime of the run session. This object can hold arbitrary state that your agent can use during the run. Tool functions just need to define a parameter called <code>run_context</code> to receive the object when they are invoked:</p> <pre><code>    def hello_func(self, run_context: RunContext, message):\n        print(message)\n        print(\"I am running in agent: \", run_context.agent.name)\n</code></pre> <p>RunContext also offers various utility methods for getting access to system services.</p>"},{"location":"Tools/#tool-return-types","title":"Tool return types","text":"<p>The most common tool simply returns a string which is provided to the LLM as the \"anwer\" to the tool call.</p> <p>However, tools can generally return any kind of object as long as it can be serialized into a string. In particular dicts and lists of dicts will be automatically serialized as JSON which most LLMs understand quite well.</p>"},{"location":"Tools/#configuration-and-secrets","title":"Configuration and Secrets","text":"<p>It is very common for tools to need some configuration or credentials in order to operate. Agentic tries to provide some framework support to cover the most common cases:</p> <pre><code>- For config, take parameters to the `__init__` function for your tool class\n- Configure secrets in the environment, but use `run_context` to access them\n- Described required secrets by implementing the `required_secrets` method\n</code></pre> <p>Here is an example from the TavilyTool (for web search):</p> <pre><code>class TavilySearchTool:\n    def __init__(self, api_key: str = None):\n        self.api_key = api_key\n\n    def required_secrets(self) -&gt; dict[str, str]:\n        return {\"TAVILY_API_KEY\": \"Tavily API key\"}\n\n    async def query_for_news(\n        self, run_context: RunContext, query: str, days_back: int = 1\n    ) -&gt; pd.DataFrame | PauseForInputResult:\n        \"\"\"Returns the latest headlines on the given topic.\"\"\"\n\n        api_key = run_context.get_secret(\"TAVILY_API_KEY\", self.api_key)\n        ...\n</code></pre> <p>You can pass the API key to the init function, but more likely you want to configure that  key in your environment. By implementing <code>required_secrets</code> you tell the framework that your tool needs some credentials, and the framework will check that they are set, or prompt the user to supply them.</p> <p>Once your tool function is called (like 'query_for_news') then you can retrieve the secrets from the RunContext. Look at Agentic's secrets system for a description of how secrets are managed.</p>"},{"location":"Tools/#using-environment-configuration","title":"Using environment configuration","text":"<p>In addition to secrets, you can store plaintext settings in your enviroment as well. Add a setting with the CLI:</p> <pre><code>agentic set &lt;setting1&gt; &lt;value1&gt;\n</code></pre> <p>and access it in your tool via <code>run_context.get</code>.</p>"},{"location":"Tools/#implementing-human-in-the-loop","title":"Implementing Human-in-the-Loop","text":"<p>Sometimes your tool will need some info from the human operator, and so your agent will need to pause to wait for that input. You can achieve this with the <code>PauseForInputResult</code> class:</p> <pre><code>from agentic.events import PauseForInputResult\n\n    def get_favorite_tv_show(self, run_context):\n        fave_tv = run_context.get_setting(\"tv_show\")\n        if fave_tv is None:\n            return PauseForInputResult({\"tv_show\": \"Please indicate your favorite TV Show\"})\n        else:\n            run_context.set_setting(\"tv_show\", fave_tv) # remember persistently\n        return f\"Ok, getting your favorite espiodes from {fave_tv}\"\n</code></pre> <p>The first time your function is called it determines that the required value is missing, so it returns the <code>PauseForInputResult</code> with the missing key and a message describing what it needs. The message will be shown to the user, and their response will be automatically set in the <code>run_context</code> using the indicated key. Then your function will be invoked again, but this time the setting should be available. You can choose to persist the value so that the human doesn't get interrupted again on the next run, via <code>run_context.set_setting</code>. </p> <p>If you want your agent to request \"human input\" directly, there is a convenience <code>HumanInterruptTool</code> available.</p>"},{"location":"Tools/#generating-events","title":"Generating Events","text":"<p>Remember that when you agent is running, it emits a stream of well-typed events. It is possible for tool functions to also generate events. In this case these events will be emitted by your agent, but they won't be revealed to the LLM. Only the actual return value from your function is returned to the LLM.</p> <p>A classic use case is generating logging events from a function:</p> <pre><code>    def long_running_function(self) -&gt; str:\n        \"\"\" Runs a long operation and returns the result. \"\"\"\n        for x in range():\n            yield ToolOutput(f\"working on row {x})\n            ... do some work\n\n        return \"The work is done! Thanks for waiting.\"\n</code></pre> <p>Adding tools dynamically</p>"}]}